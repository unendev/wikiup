"""
é¥¥è’Wikiæ•°æ®æ¸…æ´—è„šæœ¬ - ç§»é™¤å™ªéŸ³æ•°æ®
"""
import os
import re
from pathlib import Path
import shutil

def clean_wiki_markdown(content):
    """æ¸…æ´—wiki markdownå†…å®¹ - æ·±åº¦ç‰ˆ"""
    
    print("  - æ¸…æ´—å‰å­—ç¬¦æ•°:", len(content))
    
    # 1. åˆ é™¤base64å›¾ç‰‡å ä½ç¬¦
    content = re.sub(r'!\[.*?\]\(data:image/[^)]+\)', '', content)
    
    # 2. åˆ é™¤æ‰€æœ‰è§’è‰²å¼•ç”¨ï¼ˆåŒ…æ‹¬å¼•ç”¨æ–‡å­—ï¼‰
    # æ–¹å¼A: å¸¦å›¾ç‰‡çš„å®Œæ•´å¼•ç”¨
    content = re.sub(
        r'!\[\]\(data:image[^)]+\)\s*\*\*"?\*\*.*?\*\*"?\*\*\s*â€“\[.*?\]\([^)]*\)',
        '',
        content,
        flags=re.DOTALL
    )
    
    # æ–¹å¼B: åˆ é™¤è§’è‰²å¼•ç”¨æ ‡è®°
    content = re.sub(
        r'\n\*\*[""""][^*\n]+\*\*[""""]\s*\n+â€“\[[^\]]+\]\([^)]*\)\s*\n',
        '\n',
        content
    )
    
    # æ–¹å¼C: åˆ é™¤æ®‹ç•™çš„è§’è‰²æ ‡è®°
    content = re.sub(r'\n+â€“\[[^\]]+\]\([^)]*\)\s*\n', '\n', content)
    
    # æ–¹å¼D: åˆ é™¤æ‰€æœ‰è§’è‰²å¼•ç”¨æ–‡å­—ï¼ˆç²¾ç¡®åŒ¹é…ç‰ˆæœ¬ï¼‰
    # æ ¼å¼ï¼š**"**æ–‡å­—å†…å®¹**"**
    lines = content.split('\n')
    cleaned_lines = []
    for line in lines:
        stripped = line.strip()
        # ç²¾ç¡®åŒ¹é…è§’è‰²å¼•ç”¨æ ¼å¼
        if stripped.startswith('**"**') and stripped.endswith('**"**') and len(stripped) > 10:
            continue  # è·³è¿‡è§’è‰²å¼•ç”¨è¡Œ
        cleaned_lines.append(line)
    content = '\n'.join(cleaned_lines)
    
    # 3. åˆ é™¤Triviaç« èŠ‚ï¼ˆå¥‡é—»å¼‚äº‹ï¼Œå¯¹æ¸¸æˆæ”»ç•¥æ— ç”¨ï¼‰
    content = re.sub(
        r'## (?:Placeholder )?Trivia\[\].*?(?=##|\Z)',
        '',
        content,
        flags=re.DOTALL
    )
    
    # 4. åˆ é™¤åº•éƒ¨å·¨å¤§çš„å¯¼èˆªè¡¨æ ¼
    content = re.sub(
        r'\|\s+\*{3}Don\'t Starve.*?\[Craftable\].*$',
        '',
        content,
        flags=re.DOTALL
    )
    
    # 5. åˆ é™¤ç©ºçš„å¼•ç”¨é“¾æ¥
    content = re.sub(r'\*\s+\[(?:DS|RoG|SW|Ham|DST)\]\(#\)\s*\n', '', content)
    
    # 6. åˆ é™¤ Gallery ç« èŠ‚
    content = re.sub(
        r'## (?:Blueprint )?Gallery\[\].*?(?=##|\Z)',
        '',
        content,
        flags=re.DOTALL
    )
    
    # 7. åˆ é™¤ References ç« èŠ‚
    content = re.sub(
        r'## References\[\].*?(?=##|\Z)',
        '',
        content,
        flags=re.DOTALL
    )
    
    # 8. åˆ é™¤å›¾ç‰‡URLæ®‹ç•™ï¼ˆSee alsoè¡Œï¼‰
    content = re.sub(
        r'\*https://static\.wikia\.nocookie\.net/[^\s]+\s+See also:.*?\*',
        '',
        content
    )
    
    # 9. å°†è¡¨æ ¼è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€
    content = convert_tables_to_text(content)
    
    # 10. æ¸…ç†å¤šä½™ç©ºè¡Œï¼ˆè¶…è¿‡2ä¸ªè¿ç»­æ¢è¡Œï¼‰
    content = re.sub(r'\n{3,}', '\n\n', content)
    
    # 11. æ¸…ç†è¡¨æ ¼ä¸­çš„ç©ºè¡Œå’Œç©ºåˆ—
    content = re.sub(r'\|\s+\|\s*\n', '', content)
    
    # 12. åˆ é™¤é‡å¤çš„æ ‡é¢˜ï¼ˆåŒåæ ‡é¢˜åœ¨å‰10è¡Œå†…é‡å¤ï¼‰
    lines = content.split('\n')
    seen_headers = {}
    cleaned = []
    for i, line in enumerate(lines):
        stripped = line.strip()
        
        # è·³è¿‡è§’è‰²å¼•ç”¨ï¼ˆé˜²æ­¢è¢«é‡æ–°åŠ å›ï¼‰
        if stripped.startswith('**"**') and stripped.endswith('**"**') and len(stripped) > 10:
            continue
        
        # æ£€æŸ¥é‡å¤æ ‡é¢˜
        if line.startswith('## '):
            header = line.strip()
            if header in seen_headers and i - seen_headers[header] < 15:
                continue  # è·³è¿‡é‡å¤æ ‡é¢˜
            seen_headers[header] = i
        
        cleaned.append(line)
    content = '\n'.join(cleaned)
    
    print("  - æ¸…æ´—åå­—ç¬¦æ•°:", len(content))
    
    return content.strip()

def convert_tables_to_text(content):
    """å°†markdownè¡¨æ ¼è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€"""
    
    # 1. è½¬æ¢Sanityå±æ€§è¡¨æ ¼
    content = re.sub(
        r'\|\s*Sanity\s*\|\s*\n\|\s*---\s*\|\s*\n\|\s*([^|\n]+)\s*\|',
        r'**Sanity Cost:** \1',
        content
    )
    
    # 2. è½¬æ¢Effectsè¡¨æ ¼ï¼ˆDSTç‰ˆæœ¬ï¼‰
    content = re.sub(
        r'\|\s*Sanity\s*\|\s*\n\|\s*---\s*\|\s*\n\|\s*\+(\d+)\s+Summon\s+-(\d+)\s+Unsummon\s*\|',
        r'**Sanity:** +\1 when summoning, -\2 when unsummoning',
        content
    )
    
    # 3. è½¬æ¢Recipeè¡¨æ ¼
    content = re.sub(
        r'\|\s*\[Recipe\][^\|]*\|\s*\n\|\s*---\s*\|\s*\n\|\s*([^*\|]+)\*\*Ã—(\d+)\*\*\s+([^*\|]+)\*\*Ã—(\d+)\*\*\s*\|',
        r'**Recipe:** \1 (Ã—\2) + \3 (Ã—\4)',
        content
    )
    
    # 4. è½¬æ¢Perkè¡¨æ ¼
    content = re.sub(
        r'Perk\s*\n+\|\s*---\s*\|\s*\n\|\s*([^|\n]+)\s*\|',
        r'**Ability:** \1',
        content
    )
    
    # 5. è½¬æ¢Codeè¡¨æ ¼
    content = re.sub(
        r'\[Code\][^\n]*\n+\|\s*---\s*\|\s*\n\|\s*`"([^"]+)"`\s*\|',
        r'**Console Code:** `"\1"`',
        content
    )
    
    # 6. è½¬æ¢Fuel Value
    content = re.sub(
        r'### \[Fuel Value\][^\n]*\n+(\d+)/(\d+) sec',
        r'**Fuel Value:** \1 seconds (\2 sec when wet)',
        content
    )
    
    # 7. è½¬æ¢Stackså±æ€§
    content = re.sub(
        r'### Stacks up to\s*\n+Does not stack',
        r'**Stacking:** Does not stack',
        content
    )
    
    # 8. åˆ é™¤ç©ºè¡¨æ ¼æ ‡é¢˜è¡Œ
    content = re.sub(r'\|\s*\|\s*\n\|\s*---\s*\|', '', content)
    content = re.sub(r'\|\s*Inventory/Crafting\s*\|\s*\n\|\s*---\s*\|', '', content)
    
    # 9. æ¸…ç†Effectså’ŒCraftingç­‰å­¤ç«‹æ ‡é¢˜
    content = re.sub(r'\nEffects\s*\n+\*\*', r'\n**', content)
    content = re.sub(r'\nCrafting\s*\n+\*\*', r'\n**', content)
    content = re.sub(r'\nIcons\s*\n+', r'\n', content)
    
    return content

def clean_single_file(input_file, output_file):
    """æ¸…æ´—å•ä¸ªæ–‡ä»¶"""
    print(f"\nå¤„ç†: {input_file.name}")
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åˆ†ç¦» frontmatter å’Œæ­£æ–‡
        if content.startswith('---'):
            parts = content.split('---', 2)
            if len(parts) >= 3:
                frontmatter = f"---{parts[1]}---"
                body = parts[2]
            else:
                frontmatter = ""
                body = content
        else:
            frontmatter = ""
            body = content
        
        # æ¸…æ´—æ­£æ–‡
        cleaned_body = clean_wiki_markdown(body)
        
        # é‡ç»„
        final_content = f"{frontmatter}\n\n{cleaned_body}" if frontmatter else cleaned_body
        
        # ä¿å­˜
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(final_content)
        
        print(f"  âœ… æˆåŠŸä¿å­˜åˆ°: {output_file}")
        
        # è¿”å›ç»Ÿè®¡ä¿¡æ¯
        original_size = len(content)
        cleaned_size = len(final_content)
        reduction = (1 - cleaned_size / original_size) * 100 if original_size > 0 else 0
        
        return {
            'file': input_file.name,
            'original_size': original_size,
            'cleaned_size': cleaned_size,
            'reduction': reduction
        }
        
    except Exception as e:
        print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
        return None

def clean_directory(input_dir, output_dir, limit=None):
    """æ‰¹é‡æ¸…æ´—ç›®å½•ä¸‹çš„æ‰€æœ‰mdæ–‡ä»¶"""
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    if not input_path.exists():
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰mdæ–‡ä»¶
    md_files = list(input_path.glob('*.md'))
    
    if limit:
        md_files = md_files[:limit]
        print(f"\nğŸ”¬ è¯•ç‚¹æ¨¡å¼ï¼šåªå¤„ç†å‰ {limit} ä¸ªæ–‡ä»¶")
    
    total_files = len(md_files)
    print(f"\nğŸ“ æ‰¾åˆ° {total_files} ä¸ª markdown æ–‡ä»¶")
    print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {input_dir}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    print("="*80)
    
    stats = []
    
    for i, md_file in enumerate(md_files, 1):
        print(f"\n[{i}/{total_files}]", end=" ")
        output_file = output_path / md_file.name
        
        result = clean_single_file(md_file, output_file)
        if result:
            stats.append(result)
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*80)
    print("ğŸ“Š æ¸…æ´—ç»Ÿè®¡")
    print("="*80)
    
    if stats:
        total_original = sum(s['original_size'] for s in stats)
        total_cleaned = sum(s['cleaned_size'] for s in stats)
        avg_reduction = sum(s['reduction'] for s in stats) / len(stats)
        
        print(f"âœ… æˆåŠŸå¤„ç†: {len(stats)}/{total_files} ä¸ªæ–‡ä»¶")
        print(f"ğŸ“‰ åŸå§‹æ€»å¤§å°: {total_original:,} å­—ç¬¦ ({total_original/1024/1024:.2f} MB)")
        print(f"ğŸ“‰ æ¸…æ´—åå¤§å°: {total_cleaned:,} å­—ç¬¦ ({total_cleaned/1024/1024:.2f} MB)")
        print(f"ğŸ“‰ å¹³å‡å‡å°‘: {avg_reduction:.1f}%")
        print(f"ğŸ’¾ èŠ‚çœç©ºé—´: {(total_original-total_cleaned)/1024/1024:.2f} MB")
        
        # æ˜¾ç¤ºå‡å°‘æœ€å¤šçš„å‰5ä¸ªæ–‡ä»¶
        print(f"\nğŸ† å‡å°‘æœ€å¤šçš„æ–‡ä»¶:")
        top5 = sorted(stats, key=lambda x: x['reduction'], reverse=True)[:5]
        for s in top5:
            print(f"  - {s['file']}: {s['reduction']:.1f}% ({s['original_size']:,} â†’ {s['cleaned_size']:,})")
    
    print("\nâœ… æ¸…æ´—å®Œæˆï¼")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¸…æ´—é¥¥è’Wikiæ•°æ®')
    parser.add_argument('--input', '-i', 
                       default='backend/data/dst',
                       help='è¾“å…¥ç›®å½•ï¼ˆé»˜è®¤: backend/data/dstï¼‰')
    parser.add_argument('--output', '-o',
                       default='backend/data/dst_cleaned',
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: backend/data/dst_cleanedï¼‰')
    parser.add_argument('--limit', '-l',
                       type=int,
                       help='åªå¤„ç†å‰Nä¸ªæ–‡ä»¶ï¼ˆè¯•ç‚¹æ¨¡å¼ï¼‰')
    parser.add_argument('--test', '-t',
                       action='store_true',
                       help='æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†10ä¸ªæ–‡ä»¶')
    
    args = parser.parse_args()
    
    limit = args.limit
    if args.test:
        limit = 10
    
    clean_directory(args.input, args.output, limit=limit)

if __name__ == '__main__':
    main()

