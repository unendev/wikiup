"""
ä½¿ç”¨Gemini APIæ¸…æ´—é¥¥è’Wikiæ•°æ®
åªä¿ç•™å±æ€§ã€æ”»ç•¥ç­‰æ¸¸ç©ç›¸å…³å†…å®¹
"""
import os
import re
import time
import json
from pathlib import Path
from typing import Optional
import google.generativeai as genai

# Gemini APIé…ç½®
GEMINI_API_KEY = "AIzaSyCV3RYFs_9DAeRkFBxFUfcMifYx3PIz8ds"
GEMINI_MODEL = "gemini-1.5-flash"

# æ¸…æ´—æç¤ºè¯
CLEANING_PROMPT = """You are a game wiki content curator for Don't Starve Together. 
Your task is to clean the following wiki markdown content by ONLY keeping gameplay-relevant information.

**KEEP these sections:**
- Properties (stats, attributes, effects, durability)
- Crafting recipes and requirements
- Mechanics and how items/characters work
- Strategies, tips, and tactics
- Locations and spawn information
- Item tables (prices, stats, loot tables)
- Combat information
- Game mechanics explanations
- Resource gathering information

**REMOVE these sections:**
- All character quotes (e.g. "Wilson says...")
- Base64 image placeholders and image URLs
- Gallery sections
- Trivia sections
- References sections
- Navigation tables (large tables with crafting tabs)
- Blueprint Gallery
- Empty tables and empty sections
- Social media links
- Version history
- Bug sections

**Additional cleaning rules:**
1. Keep the frontmatter (YAML metadata between ---) unchanged
2. Remove all base64 image data: ![](data:image/...)
3. Remove character quotes that start with **"** and end with **"**
4. Remove attribution lines like "â€“[Wilson](/wiki/Wilson)"
5. Convert tables to clean readable format when possible
6. Keep markdown formatting for readability
7. Remove empty headings (## Heading[] with no content)

Please output ONLY the cleaned markdown content, preserving the structure and formatting of gameplay-relevant information.

---
ORIGINAL CONTENT:
"""

def init_gemini():
    """åˆå§‹åŒ–Gemini API"""
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(GEMINI_MODEL)
    return model

def clean_with_gemini(content: str, model) -> Optional[str]:
    """ä½¿ç”¨Geminiæ¸…æ´—å†…å®¹"""
    try:
        # å¦‚æœå†…å®¹å¤ªçŸ­ï¼Œç›´æ¥è¿”å›
        if len(content) < 100:
            return content
        
        # å‘é€è¯·æ±‚åˆ°Gemini
        prompt = CLEANING_PROMPT + content
        
        # é…ç½®ç”Ÿæˆå‚æ•°
        generation_config = {
            "temperature": 0.1,  # ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„è¾“å‡º
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 8192,
        }
        
        response = model.generate_content(
            prompt,
            generation_config=generation_config
        )
        
        # è·å–æ¸…æ´—åçš„å†…å®¹
        cleaned_content = response.text
        
        # åå¤„ç†ï¼šç¡®ä¿frontmatterå­˜åœ¨
        if content.startswith('---') and not cleaned_content.startswith('---'):
            # æå–åŸå§‹frontmatter
            parts = content.split('---', 2)
            if len(parts) >= 3:
                frontmatter = f"---{parts[1]}---"
                cleaned_content = f"{frontmatter}\n\n{cleaned_content}"
        
        return cleaned_content
        
    except Exception as e:
        print(f"    âŒ Gemini APIé”™è¯¯: {e}")
        return None

def clean_single_file(input_file: Path, output_file: Path, model) -> dict:
    """æ¸…æ´—å•ä¸ªæ–‡ä»¶"""
    print(f"\nå¤„ç†: {input_file.name}")
    
    try:
        # è¯»å–åŸå§‹å†…å®¹
        with open(input_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_size = len(content)
        print(f"  - åŸå§‹å¤§å°: {original_size:,} å­—ç¬¦")
        
        # ä½¿ç”¨Geminiæ¸…æ´—
        print(f"  - æ­£åœ¨è°ƒç”¨Gemini APIæ¸…æ´—...")
        cleaned_content = clean_with_gemini(content, model)
        
        if cleaned_content is None:
            print(f"  âŒ æ¸…æ´—å¤±è´¥ï¼Œè·³è¿‡")
            return None
        
        cleaned_size = len(cleaned_content)
        reduction = (1 - cleaned_size / original_size) * 100 if original_size > 0 else 0
        
        print(f"  - æ¸…æ´—åå¤§å°: {cleaned_size:,} å­—ç¬¦")
        print(f"  - å‡å°‘: {reduction:.1f}%")
        
        # ä¿å­˜æ¸…æ´—åçš„å†…å®¹
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(cleaned_content)
        
        print(f"  âœ… æˆåŠŸä¿å­˜åˆ°: {output_file.name}")
        
        return {
            'file': input_file.name,
            'original_size': original_size,
            'cleaned_size': cleaned_size,
            'reduction': reduction,
            'success': True
        }
        
    except Exception as e:
        print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
        return {
            'file': input_file.name,
            'success': False,
            'error': str(e)
        }

def clean_directory(input_dir: str, output_dir: str, limit: Optional[int] = None, 
                    delay: float = 1.0, resume_from: Optional[str] = None):
    """æ‰¹é‡æ¸…æ´—ç›®å½•ä¸‹çš„æ‰€æœ‰mdæ–‡ä»¶"""
    
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    if not input_path.exists():
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path.mkdir(parents=True, exist_ok=True)
    
    # åˆå§‹åŒ–Gemini
    print("ğŸ”§ åˆå§‹åŒ–Gemini API...")
    model = init_gemini()
    print("âœ… Gemini APIå·²åˆå§‹åŒ–")
    
    # è·å–æ‰€æœ‰mdæ–‡ä»¶
    md_files = sorted(list(input_path.glob('*.md')))
    
    # å¦‚æœæŒ‡å®šäº†resume_fromï¼Œè·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶
    if resume_from:
        try:
            resume_idx = [f.name for f in md_files].index(resume_from)
            md_files = md_files[resume_idx:]
            print(f"\nğŸ“Œ ä»æ–‡ä»¶ '{resume_from}' æ¢å¤å¤„ç†")
        except ValueError:
            print(f"\nâš ï¸  æ‰¾ä¸åˆ°æ¢å¤ç‚¹æ–‡ä»¶ '{resume_from}'ï¼Œä»å¤´å¼€å§‹")
    
    if limit:
        md_files = md_files[:limit]
        print(f"\nğŸ”¬ é™åˆ¶æ¨¡å¼ï¼šåªå¤„ç† {limit} ä¸ªæ–‡ä»¶")
    
    total_files = len(md_files)
    print(f"\nğŸ“ å…±æ‰¾åˆ° {total_files} ä¸ª markdown æ–‡ä»¶")
    print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {input_dir}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"â±ï¸  APIè°ƒç”¨é—´éš”: {delay}ç§’")
    print("="*80)
    
    stats = []
    failed_files = []
    
    for i, md_file in enumerate(md_files, 1):
        print(f"\n[{i}/{total_files}]", end=" ")
        output_file = output_path / md_file.name
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
        if output_file.exists():
            print(f"â­ï¸  è·³è¿‡å·²å­˜åœ¨: {md_file.name}")
            continue
        
        result = clean_single_file(md_file, output_file, model)
        
        if result:
            if result.get('success'):
                stats.append(result)
            else:
                failed_files.append(result)
        
        # APIé™é€Ÿï¼šé¿å…è§¦å‘é…é¢é™åˆ¶
        if i < total_files:
            print(f"  â³ ç­‰å¾… {delay} ç§’...")
            time.sleep(delay)
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*80)
    print("ğŸ“Š æ¸…æ´—ç»Ÿè®¡")
    print("="*80)
    
    if stats:
        total_original = sum(s['original_size'] for s in stats)
        total_cleaned = sum(s['cleaned_size'] for s in stats)
        avg_reduction = sum(s['reduction'] for s in stats) / len(stats)
        
        print(f"âœ… æˆåŠŸå¤„ç†: {len(stats)}/{total_files} ä¸ªæ–‡ä»¶")
        print(f"ğŸ“‰ åŸå§‹æ€»å¤§å°: {total_original:,} å­—ç¬¦ ({total_original/1024/1024:.2f} MB)")
        print(f"ğŸ“‰ æ¸…æ´—åå¤§å°: {total_cleaned:,} å­—ç¬¦ ({total_cleaned/1024/1024:.2f} MB)")
        print(f"ğŸ“‰ å¹³å‡å‡å°‘: {avg_reduction:.1f}%")
        print(f"ğŸ’¾ èŠ‚çœç©ºé—´: {(total_original-total_cleaned)/1024/1024:.2f} MB")
        
        # æ˜¾ç¤ºå‡å°‘æœ€å¤šçš„å‰5ä¸ªæ–‡ä»¶
        print(f"\nğŸ† å‡å°‘æœ€å¤šçš„æ–‡ä»¶:")
        top5 = sorted(stats, key=lambda x: x['reduction'], reverse=True)[:5]
        for s in top5:
            print(f"  - {s['file']}: {s['reduction']:.1f}% ({s['original_size']:,} â†’ {s['cleaned_size']:,})")
    
    if failed_files:
        print(f"\nâŒ å¤±è´¥çš„æ–‡ä»¶ ({len(failed_files)}):")
        for f in failed_files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  - {f['file']}: {f.get('error', 'Unknown error')}")
        if len(failed_files) > 10:
            print(f"  ... è¿˜æœ‰ {len(failed_files) - 10} ä¸ªå¤±è´¥")
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats_file = output_path / '_cleaning_stats.json'
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump({
            'total_files': total_files,
            'successful': len(stats),
            'failed': len(failed_files),
            'stats': stats,
            'failed_files': failed_files
        }, f, indent=2, ensure_ascii=False)
    print(f"\nğŸ“„ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_file}")
    
    print("\nâœ… æ¸…æ´—å®Œæˆï¼")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ä½¿ç”¨Gemini APIæ¸…æ´—é¥¥è’Wikiæ•°æ®',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†5ä¸ªæ–‡ä»¶
  python gemini_clean_wiki.py --test
  
  # å¤„ç†æ‰€æœ‰æ–‡ä»¶
  python gemini_clean_wiki.py
  
  # å¤„ç†å‰50ä¸ªæ–‡ä»¶
  python gemini_clean_wiki.py --limit 50
  
  # ä»ç‰¹å®šæ–‡ä»¶æ¢å¤å¤„ç†
  python gemini_clean_wiki.py --resume "some-file.md"
  
  # è‡ªå®šä¹‰è¾“å…¥è¾“å‡ºç›®å½•
  python gemini_clean_wiki.py -i backend/data/dst -o backend/data/dst_deep
        """
    )
    
    parser.add_argument('--input', '-i', 
                       default='backend/data/dst',
                       help='è¾“å…¥ç›®å½•ï¼ˆé»˜è®¤: backend/data/dstï¼‰')
    parser.add_argument('--output', '-o',
                       default='backend/data/dst_deep',
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: backend/data/dst_deepï¼‰')
    parser.add_argument('--limit', '-l',
                       type=int,
                       help='åªå¤„ç†å‰Nä¸ªæ–‡ä»¶')
    parser.add_argument('--test', '-t',
                       action='store_true',
                       help='æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†5ä¸ªæ–‡ä»¶')
    parser.add_argument('--delay', '-d',
                       type=float,
                       default=1.0,
                       help='APIè°ƒç”¨é—´éš”ï¼ˆç§’ï¼Œé»˜è®¤1.0ï¼‰')
    parser.add_argument('--resume', '-r',
                       type=str,
                       help='ä»æŒ‡å®šæ–‡ä»¶åæ¢å¤å¤„ç†')
    
    args = parser.parse_args()
    
    limit = args.limit
    if args.test:
        limit = 5
    
    clean_directory(
        args.input, 
        args.output, 
        limit=limit,
        delay=args.delay,
        resume_from=args.resume
    )

if __name__ == '__main__':
    main()



