# WikiUp：企业级AI知识库问答平台 (简历项目描述)

---

### **版本一：完整版 (适用于重点项目展示)**

**项目名称：** WikiUp - 基于RAG的企业级智能知识库平台

**项目描述：**
该项目是一个基于检索增强生成（RAG）架构，面向企业内部知识库的智能问答平台。平台通过深度学习模型对非结构化的Markdown文档（如产品手册、技术Wiki）进行处理，构建向量化知识索引，并允许用户通过自然语言对话的方式进行高效、精准的信息检索。项目采用前后端分离的全栈架构，后端基于Spring Boot，前端基于Vue 3，通过WebSocket实现AI回答的实时流式传输，旨在提供企业级的智能信息服务。

**核心技术：**
*   **后端：** Spring Boot, Spring Security, WebSocket, DJL, PyTorch, CompletableFuture, Redis, Docker
*   **前端：** Vue 3, TypeScript, Pinia, Vue Router, Axios, WebSocket, Tailwind CSS
*   **AI模型：** `paraphrase-multilingual-MiniLM-L12-v2` (文本嵌入), DeepSeek API (文本生成)

**个人职责与项目业绩：**
*   **RAG核心引擎设计与实现：** 独立负责并实现了完整的RAG（检索增强生成）核心链路。从文档的语义化文本分块、使用DJL加载深度学习模型进行向量化，到构建基于HNSW算法的内存向量数据库，实现了高效的相似度检索，并主导了Prompt工程优化，显著提升了问答的相关性和准确性。
*   **高性能后端架构与开发：** 作为后端负责人，基于Spring Boot从零构建了整个应用。采用分层架构（Controller/DTO/Service）和依赖注入保证了代码的可维护性和扩展性。利用`CompletableFuture`和自定义线程池设计并实现了文档处理的异步并行化，将大规模知识库的初始构建时间缩短了XX%。
*   **系统安全与授权：** 基于Spring Security和JWT设计并实现了完整的认证授权体系。通过自定义Filter链和RBAC（基于角色的访问控制）模型，为后台管理API提供了精细化的权限控制，保障了系统的安全。
*   **服务性能优化：** 引入Redis作为二级缓存，对高频查询的向量嵌入结果和LLM生成的回答进行缓存。通过优化缓存策略，使重复查询场景下的系统响应延迟降低了XX%，同时有效减少了对下游AI服务的API调用成本。
*   **现代化前端开发：** 独立完成了前端应用的全部开发工作。采用Vue 3 Composition API和TypeScript构建了类型安全、响应式的单页应用。通过Pinia进行集中的状态管理，并利用WebSocket实现了AI回答的流式打字机效果，大幅提升了用户交互体验。
*   **容器化与部署实践：** 负责应用的容器化工作，编写了多阶段构建的Dockerfile以减小镜像体积，并使用Docker Compose对前端、后端及Redis服务进行编排，实现了一键化本地部署，保证了开发与生产环境的一致性。

---

### **版本二：精简版 (适用于简历空间有限的情况)**

**项目名称：** WikiUp - 基于RAG与Spring Boot的全栈AI知识库平台

**项目描述：**
独立设计并开发了一款企业级智能知识库问答平台。该平台采用RAG架构，支持对海量Markdown文档进行语义理解和智能问答。项目为前后端分离的全栈应用，后端使用Spring Boot，前端使用Vue 3，通过WebSocket实现实时流式响应。

**个人职责与项目业绩：**
*   独立设计并实现RAG核心引擎，包括文本向量化、HNSW相似度检索和Prompt工程。
*   基于Spring Boot和`CompletableFuture`搭建高性能后端，实现文档异步并行处理。
*   使用Spring Security与JWT构建RBAC权限体系，集成Redis缓存优化系统性能。
*   独立开发Vue 3前端应用，使用TypeScript确保类型安全，通过WebSocket实现流式通信。
*   利用Docker与Docker Compose完成应用的容器化封装，实现快速部署。 